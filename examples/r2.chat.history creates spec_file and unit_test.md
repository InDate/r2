
# r2 chat started at 2023-05-24 17:46:34

> /Users/joshua/Documents/Code/R2/r2/main.py  
> Test directory found: /Users/joshua/Documents/Code/R2/tests/  

#### /test_connection  
> Prompt Tokens: 13  
> Total running cost: $0.000  

Why did the computer go to the doctor? Because it had a #####!

# r2 chat started at 2023-05-24 18:13:00

> /Users/joshua/Documents/Code/R2/r2/main.py  
> Test directory found: /Users/joshua/Documents/Code/R2/tests/  
> No commit message found, generating...  
> Prompt Tokens: 430  
> Total running cost: $0.001  
> Git repo has uncommitted changes.  
> Suggested commit message [commit message]: Added Timeout exception handling to ApiManager.  
> Test changes to r2/coder_classes/api_manager.py [y/n]]? y  
> Test file: tests/coder_classes/test_api_manager.py not found, queue create test? y  
> Spec file: spec/coder_classes/spec_api_manager.md not found, create before commit [y/n]? y  
> Commit c6c0c6a Added Timeout exception handling to ApiManager.  
> Added r2/coder_classes/api_manager.py to the chat  
> Prompt Tokens: 2269  
> Total running cost: $0.082  

```markdown
spec/coder_classes/spec_api_manager.md
<<<<<<< ORIGINAL
=======
- Class Name: ApiManager
- Purpose: Manage API calls to OpenAI, track tokens, and handle errors.

- Properties:
    - `total_prompt_tokens`: The total number of prompt tokens used.
    - `total_completion_tokens`: The total number of completion tokens used.
    - `total_cost`: The total cost of API calls.
    - `total_budget`: The total user-defined budget for API calls.
    - `prompt_tokens`: The number of prompt tokens for the current API call.
    - `completion_tokens`: The number of completion tokens for the current API call.

- Methods:
    - `reset()`: Resets the total tokens and cost.
    - `create_chat_completion(messages, model, temperature, max_tokens, stream)`: Creates a chat completion and updates the cost.
    - `update_cost(model)`: Updates the total cost, prompt tokens, and completion tokens.
    - `get_approx_prompt_tokens(messages, model)`: Gets the approximate number of prompt tokens for the given messages and model.
    - `update_prompt_tokens(messages, model)`: Updates the number of prompt tokens for the current API call.
    - `update_completion_tokens(completion_tokens)`: Updates the number of completion tokens for the current API call.
    - `set_total_budget(total_budget)`: Sets the total user-defined budget for API calls.
    - `get_total_prompt_tokens()`: Returns the total number of prompt tokens.
    - `get_total_completion_tokens()`: Returns the total number of completion tokens.
    - `get_total_cost()`: Returns the total cost of API calls.
    - `get_total_budget()`: Returns the total user-defined budget for API calls.

- Example Usage:
api_manager = ApiManager()
api_manager.set_total_budget(10)
messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}]
response = api_manager.create_chat_completion(messages, model="text-davinci-002", temperature=0.5, max_tokens=50)
print(api_manager.get_total_cost())  # Outputs: Total running cost: $0.123
>>>>>>> UPDATED
```

> Allow creation of new file spec/coder_classes/spec_api_manager.md? y  
> Add spec/coder_classes/spec_api_manager.md to git? y  
> Applied edit to spec/coder_classes/spec_api_manager.md  
> No commit message found, generating...  
> Prompt Tokens: 1879  
> Total running cost: $0.093  
> Commit 7b2b680 Added ApiManager class with properties and methods for managing API calls to OpenAI, tracking tokens, and handling errors.  
> Prompt Tokens: 2651  
> Total running cost: $0.340  

To test the `ApiManager` class in `r2/coder_classes/api_manager.py`, we can use the `unittest` library to create test cases. We will mock the OpenAI API calls using the `unittest.mock` library to avoid making actual API calls during testing.

Here's the approach we will take:

1. Test the `reset()` method to ensure it resets the total tokens and cost.
2. Test the `create_chat_completion()` method by mocking the OpenAI API call and checking if the cost is updated correctly.
3. Test the `update_cost()` method by providing different models and checking if the cost is updated correctly.
4. Test the `get_approx_prompt_tokens()` method by providing different messages and models and checking if the prompt tokens are calculated correctly.
5. Test the `update_prompt_tokens()` method by providing different messages and models and checking if the prompt tokens are updated correctly.
6. Test the `update_completion_tokens()` method by providing different completion tokens and checking if the completion tokens are updated correctly.
7. Test the `set_total_budget()` and `get_total_budget()` methods by setting and getting the total budget.
8. Test the `get_total_prompt_tokens()`, `get_total_completion_tokens()`, and `get_total_cost()` methods by checking their return values.

Now, let's create the actual tests in `tests/coder_classes/test_api_manager.py`:

```python
tests/coder_classes/test_api_manager.py
<<<<<<< ORIGINAL
=======
import unittest
from unittest.mock import patch
from r2.coder_classes.api_manager import ApiManager, TokensExceedsModel

class TestApiManager(unittest.TestCase):
    def setUp(self):
        self.api_manager = ApiManager()

    def test_reset(self):
        self.api_manager.reset()
        self.assertEqual(self.api_manager.get_total_prompt_tokens(), 0)
        self.assertEqual(self.api_manager.get_total_completion_tokens(), 0)
        self.assertEqual(self.api_manager.get_total_cost(), "Total running cost: $0.000")

    @patch("r2.coder_classes.api_manager.openai.ChatCompletion.create")
    def test_create_chat_completion(self, mock_create):
        mock_create.return_value = {"choices": [{"text": "Paris"}]}
        messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}]
        response = self.api_manager.create_chat_completion(messages, model="text-davinci-002", temperature=0.5, max_tokens=50)
        self.assertEqual(response, {"choices": [{"text": "Paris"}]})
        self.assertNotEqual(self.api_manager.get_total_cost(), "Total running cost: $0.000")

    def test_update_cost(self):
        self.api_manager.update_cost("text-davinci-002")
        self.assertNotEqual(self.api_manager.get_total_cost(), "Total running cost: $0.000")

    def test_get_approx_prompt_tokens(self):
        messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}]
        prompt_tokens = self.api_manager.get_approx_prompt_tokens(messages, "text-davinci-002")
        self.assertEqual(prompt_tokens, 50)

    def test_update_prompt_tokens(self):
        messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}]
        self.api_manager.update_prompt_tokens(messages, "text-davinci-002")
        self.assertEqual(self.api_manager.prompt_tokens, 50)

    def test_update_completion_tokens(self):
        self.api_manager.update_completion_tokens(10)
        self.assertEqual(self.api_manager.completion_tokens, 10)

    def test_set_get_total_budget(self):
        self.api_manager.set_total_budget(10)
        self.assertEqual(self.api_manager.get_total_budget(), 10)

    def test_get_total_prompt_tokens(self):
        self.assertEqual(self.api_manager.get_total_prompt_tokens(), 0)

    def test_get_total_completion_tokens(self):
        self.assertEqual(self.api_manager.get_total_completion_tokens(), 0)

    def test_get_total_cost(self):
        self.assertEqual(self.api_manager.get_total_cost(), "Total running cost: $0.000")

if __name__ == "__main__":
    unittest.main()
>>>>>>> UPDATED
```

This test suite covers the main functionality of the `ApiManager` class. You can run the tests using the command `python -m unittest tests/coder_classes/test_api_manager.py`.

> Allow creation of new file tests/coder_classes/test_api_manager.py? y  
> Add tests/coder_classes/test_api_manager.py to git? y  
> Applied edit to tests/coder_classes/test_api_manager.py  
> No commit message found, generating...  
> Prompt Tokens: 2677  
> Total running cost: $0.362  
> Commit c6e75d1 Added unit tests for the `ApiManager` class in `r2/coder_classes/api_manager.py`.  